{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO73UIVjQw29rzfHVCGq9vC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kurehajime/openapi_sandbox/blob/main/HackerNews%E3%82%92%E6%97%A5%E6%9C%AC%E8%AA%9E%E3%81%A7%E8%AA%AD%E3%81%BF%E3%81%9F%E3%81%84.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "以下の入力ボックスにOpenAIのAPIキーを入力してください。"
      ],
      "metadata": {
        "id": "jQAsFtprhmTa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "secret = getpass('Enter the secret value: ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJvCYXRGayAd",
        "outputId": "0eaabde5-e030-4eaf-f554-e5d0af3c1643"
      },
      "execution_count": 13,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the secret value: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHuQn5XpWe57",
        "outputId": "9dd0ed84-35f6-4430-a661-01e98dc35a0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: feedparser in /usr/local/lib/python3.9/dist-packages (6.0.10)\n",
            "Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.9/dist-packages (from feedparser) (1.0.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.9/dist-packages (0.3.1)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.9/dist-packages (from tiktoken) (2.28.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.9/dist-packages (from tiktoken) (2022.6.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken) (2.10)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken) (3.1.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken) (2022.12.7)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting newspaper3k\n",
            "  Downloading newspaper3k-0.2.8-py3-none-any.whl (211 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.1/211.1 KB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tinysegmenter==0.3\n",
            "  Downloading tinysegmenter-0.3.tar.gz (16 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.9/dist-packages (from newspaper3k) (6.0)\n",
            "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.9/dist-packages (from newspaper3k) (4.9.3)\n",
            "Requirement already satisfied: feedparser>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from newspaper3k) (6.0.10)\n",
            "Requirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.9/dist-packages (from newspaper3k) (4.9.2)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.9/dist-packages (from newspaper3k) (2.8.2)\n",
            "Requirement already satisfied: nltk>=3.2.1 in /usr/local/lib/python3.9/dist-packages (from newspaper3k) (3.7)\n",
            "Collecting tldextract>=2.0.1\n",
            "  Downloading tldextract-3.4.0-py3-none-any.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.9/93.9 KB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cssselect>=0.9.2\n",
            "  Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
            "Collecting feedfinder2>=0.0.4\n",
            "  Downloading feedfinder2-0.0.4.tar.gz (3.3 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.9/dist-packages (from newspaper3k) (8.4.0)\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.9/dist-packages (from newspaper3k) (2.28.2)\n",
            "Collecting jieba3k>=0.35.1\n",
            "  Downloading jieba3k-0.35.1.zip (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4>=4.4.1->newspaper3k) (2.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from feedfinder2>=0.0.4->newspaper3k) (1.15.0)\n",
            "Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.9/dist-packages (from feedparser>=5.2.1->newspaper3k) (1.0.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk>=3.2.1->newspaper3k) (8.1.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk>=3.2.1->newspaper3k) (2022.6.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from nltk>=3.2.1->newspaper3k) (4.65.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk>=3.2.1->newspaper3k) (1.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.10.0->newspaper3k) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.10.0->newspaper3k) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.10.0->newspaper3k) (2.10)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests>=2.10.0->newspaper3k) (3.1.0)\n",
            "Collecting requests-file>=1.4\n",
            "  Downloading requests_file-1.5.1-py2.py3-none-any.whl (3.7 kB)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.9/dist-packages (from tldextract>=2.0.1->newspaper3k) (3.9.0)\n",
            "Building wheels for collected packages: tinysegmenter, feedfinder2, jieba3k\n",
            "  Building wheel for tinysegmenter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-py3-none-any.whl size=13553 sha256=ad472807f1c6a5601e2c7c78ce8e74f3d30b9ba1a02b61bfa667eac715a3b400\n",
            "  Stored in directory: /root/.cache/pip/wheels/94/ad/df/a2a01300cea47d5695f242f7e925a805970106fd9e4b151468\n",
            "  Building wheel for feedfinder2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-py3-none-any.whl size=3355 sha256=642a4901a1cb6fe6bbaf87aad1401ab07155827039de57d7709a24c664361f02\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/4a/c2/61a371b2524ac90805391c660d8dc4505705297f25e2b85a5d\n",
            "  Building wheel for jieba3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jieba3k: filename=jieba3k-0.35.1-py3-none-any.whl size=7398404 sha256=9ef8fa36fb981dd3eaf9723a8500339c640bd27b500089211d78f366db70a3e8\n",
            "  Stored in directory: /root/.cache/pip/wheels/c2/22/59/8214a8d6357e9f540ce1f37f9a4362b6156b4ca81b37f1945f\n",
            "Successfully built tinysegmenter feedfinder2 jieba3k\n",
            "Installing collected packages: tinysegmenter, jieba3k, cssselect, requests-file, feedfinder2, tldextract, newspaper3k\n",
            "Successfully installed cssselect-1.2.0 feedfinder2-0.0.4 jieba3k-0.35.1 newspaper3k-0.2.8 requests-file-1.5.1 tinysegmenter-0.3 tldextract-3.4.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.2-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 KB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/dist-packages (from openai) (2.28.2)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (22.2.0)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.2 yarl-1.8.2\n"
          ]
        }
      ],
      "source": [
        "!pip install feedparser\n",
        "!pip install tiktoken\n",
        "!pip install newspaper3k\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import feedparser\n",
        "def get_entries(url):\n",
        "  feed = feedparser.parse(url)\n",
        "  entries = []\n",
        "  for entry in feed['entries']:\n",
        "    entries.append({\n",
        "        \"title\":entry['title'],\n",
        "        \"link\":entry['link'],\n",
        "        \"comments\":entry['comments'],\n",
        "    })\n",
        "  return entries"
      ],
      "metadata": {
        "id": "1HQmBv0RXYX2"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from newspaper import Article\n",
        "def get_news(url):\n",
        "  article = Article(url)\n",
        "  article.download()\n",
        "  article.parse()\n",
        "  return article.text"
      ],
      "metadata": {
        "id": "gJuqNCY2Yxp3"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
        "def get_head_by_token(text,head_size,sep):\n",
        "  lines = text.split(sep)\n",
        "  blocks = []\n",
        "  token = 0\n",
        "  block = ''\n",
        "  for line in lines:\n",
        "    t = len(encoding.encode(line))\n",
        "    if token > 0 and head_size < (token + t):\n",
        "      return block\n",
        "    token += t\n",
        "    block += line\n",
        "  return block"
      ],
      "metadata": {
        "id": "xzSoxNSSaAOp"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "url = \"https://hnrss.org/newest?points=100\"\n",
        "entries = get_entries(url)\n",
        "openai.api_key = secret\n",
        "output = \"\"\n",
        "for entry in entries[:5]:\n",
        "  text = get_news(entry[\"link\"])\n",
        "  head = get_head_by_token(text,1000,\"\\n\")\n",
        "  completion = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "          {\"role\": \"user\", \"content\": f\"\"\"\n",
        "以下の文章を日本語に翻訳して3行に要約してください。\n",
        "---\n",
        "{head}\n",
        "          \"\"\"},\n",
        "      ]\n",
        "  )\n",
        "  sumally = \"\"\n",
        "  for cho in completion.choices:\n",
        "    sumally += cho.message.content\n",
        "    output += f\"\"\"\n",
        "### [{entry[\"title\"]}]({entry[\"comments\"]})\n",
        "{sumally}\n",
        "    \"\"\"\n",
        "  \n",
        "from IPython.display import display, Markdown\n",
        "display(Markdown(output))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "dqtupn6daZxv",
        "outputId": "a87e3c64-a906-42f7-ab23-9e4ab3905ce5"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n### [Google discontinues Google Glass for enterprise](https://news.ycombinator.com/item?id=35178986)\n\n\n「10年以上にわたる革新とパートナーシップに感謝します。2023年3月15日をもって、Glass Enterprise Editionの販売を終了します。2023年9月15日までは引き続きサポートを提供します。詳細はヘルプセンターをご覧ください。」\n\n- Glass Enterprise Editionの販売終了（2023年3月15日）\n- サポートは2023年9月15日まで提供\n- 詳細はヘルプセンターを確認\n    \n### [GPT-4 Designed a Programming Language](https://news.ycombinator.com/item?id=35177857)\nGPT-4がリリースされ、AI競争が加速している中、多くの人々は興奮と恐怖を感じている。GPT-4は専門家の中でも優秀な人々が驚くほど素晴らしいものを生み出しており、その進化はとどまるところを知らない。この進化を楽しむものと恐れるものがある中、筆者はGPT-4のチャットのベータ版に選ばれ、4時までプレイしていた。\n\nGPT-4のリリースにより、AI競争は加速する一方であり、それは喜びと恐怖を共有する人々に影響を与えている。筆者自身もGPT-4のチャットのベータ版に選ばれ、様々なプログラム言語について学んだが、GPT-4はプログラム言語を設計するという高度な課題にも取り組んでいる。\n    \n### [Will AIs take all our jobs and end human history? It’s complicated](https://news.ycombinator.com/item?id=35177257)\n文章ではAIのChatGPTについて説明し、人間によって書かれたテキストから学び、人間に似たエッセイを自動生成できることを示しています。ChatGPTは「共有コンテキスト」を基に、文字のプロンプトに基づいてエッセイを生成することができます。この技術により、人間が行っていた翻訳やエッセイ作成などの作業が自動化されることが期待されます。\n    \n### [Fireball Spotted over Northeastern USA](https://news.ycombinator.com/item?id=35175805)\nThe company has been working on a new product for the past year, and they are finally ready to launch it into the market. The product is expected to be a game-changer in its industry and the company is confident in its success. The launch date is set for next month and the company is already receiving pre-orders from interested customers.\n\n1.新製品の開発が完了し、来月の発売日を迎える予定。\n2.業界に革命をもたらすと期待され、注文も既に受け付け中。\n3.会社は成功を確信している。\n    \n### [Emulating Pokemon Emerald on GPT-4](https://news.ycombinator.com/item?id=35175321)\nJavaScriptが利用できません。このブラウザではJavaScriptが無効になっていることが検出されました。続けるにはJavaScriptを有効にするか、サポートされているブラウザに切り替えてください。サポートされているブラウザのリストは、ヘルプセンターで確認できます。 \n\nJavaScriptが無効なため、Twitter.comの利用ができない。ブラウザを切り替えてあるいはJavaScriptを有効にしてください。\n    "
          },
          "metadata": {}
        }
      ]
    }
  ]
}